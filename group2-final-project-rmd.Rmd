---
title: "IS 517 - Methods of Data Science - Diabetes Prediction"
author: "Yashashri Haryan, Mrunal Gadge and Shabeeha Ahmed"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(RCurl)
library(funModeling)
#install.packages('dbplyr')
library(tidyverse) 
library(Hmisc)
library(readr)
#install.packages('caret')
library(caret)
library(e1071)
library(rpart)
```

```{r}
#loading data

binarydata <- read.csv("diabetes_binary_5050split_health_indicators_BRFSS2015.csv")


head(binarydata,5)
dim(binarydata)
summary(binarydata)
str(binarydata)
```

```{r}
##### Bar plot for HighBP and Diabetes_binary#####

counts <- table(binarydata$HighBP, binarydata$Diabetes_binary)
counts
# get percentages of vars

pcnts <- scale(counts, FALSE, colSums(counts))*100
pcnts
# plot barplot

bp <- barplot(pcnts, beside=TRUE, col=c("lightblue","red"),xlab="BP - No Diabetes vs Diabetes", ylab="Frequency (%)", border=NA)
legend("top",xpd=TRUE, legend=c("Low BP", "High BP"), bty="n", fill=c("lightblue", "red"), border=NA)
text(bp, 1, round(pcnts, 2), cex=1, pos=3, col=c("black"))
```

```{r}

##### Histogram for BMI and patients with diabetes #####

DiabetesRows =filter(binarydata, Diabetes_binary == 1)
NonDiabetesRows =filter(binarydata, Diabetes_binary == 0)
hist_BMI <- DiabetesRows$BMI
hist(hist_BMI,
     main="BMI ranges of people with diabetes",
     xlab="BMI Range",
     xlim=c(10,60),
     col="darkmagenta",
     freq=FALSE)

#BMI of people without diabetes
NonDiabetesRows =filter(binarydata, Diabetes_binary == 0)
hist_BMI <- NonDiabetesRows$BMI
hist(hist_BMI,
     main="BMI ranges of people without diabetes",
     xlab="BMI Range",
     xlim=c(10,60),
     col="darkmagenta",
     freq=FALSE)

### histogram of diabetes and general health
hist_genHlth <- DiabetesRows$GenHlth
hist(hist_genHlth,
     main="GenHlth of people with diabetes",
     xlab="General Health",
     col="red",
     freq=FALSE)

### histogram of non diabetes and general health
hist_genHlth <- NonDiabetesRows$GenHlth
hist(hist_genHlth,
     main="GenHlth of people without diabetes",
     xlab="General Health",
     col="red",
     freq=FALSE)
```

```{r}

###### Bar graph to compare Heart disease or attack with diabetes #####
counts <- table(binarydata$HeartDiseaseorAttack, binarydata$Diabetes_binary)
counts
# get percentages of vars
pcnts <- scale(counts, FALSE, colSums(counts))*100
pcnts
# plot barplot
bp <- barplot(pcnts, beside=TRUE, col=c("lightblue","red"),xlab="Heart disease in No Diabetes vs Diabetes", ylab="Frequency (%)", border=NA)
legend("top", legend=c("No Heart Disease", "Heart Disease"), bty="n", fill=c("lightblue", "red"), border=NA)
text(bp, 1, round(pcnts, 2), cex=1, pos=3, col=c("black"))

####### Bar graph for HighChol ########
counts <- table(binarydata$HighChol, binarydata$Diabetes_binary)
counts
# get percentages of vars
pcnts <- scale(counts, FALSE, colSums(counts))*100
pcnts
# plot barplot
bp <- barplot(pcnts, beside=TRUE, col=c("lightblue","red"),xlab="Cholestrol in No Diabetes vs Diabetes", ylab="Frequency (%)", border=NA)
legend("top",legend=c("Normal Cholestrol", "High Cholestrol"), bty="n", fill=c("lightblue", "red"), border=NA)
text(bp, 1, round(pcnts, 2), cex=1, pos=3, col=c("black"))

###### Bar graph to compare sex and diabetes ######
counts <- table(binarydata$Sex, binarydata$Diabetes_binary)
counts
# get percentages of vars
pcnts <- scale(counts, FALSE, colSums(counts))*100
pcnts
# plot barplot
bp <- barplot(pcnts, beside=TRUE, col=c("lightblue","red"),xlab="Sex of people with and without diabetes", ylab="Frequency (%)", border=NA)
legend(x="top", legend=c("Female", "Male"), bty="n", fill=c("lightblue", "red"), border=NA)
text(bp, 1, round(pcnts, 2), cex=1, pos=3, col=c("black"))

```

```{r}
###### Histogram of ages of people with diabetes ###### 
hist_genHlth <- DiabetesRows$Age
hist(hist_genHlth,
     main="Age of people with diabetes",
     xlab="Categorical Age",
     col="red",
     freq=FALSE)
####
```
#View(binarydata)

```{r}
library(DataExplorer)

plot_correlation(binarydata)

binarydata$HighBP  = as.factor(binarydata$HighBP)
binarydata$HighChol  = as.factor(binarydata$HighChol)
binarydata$CholCheck  = as.factor(binarydata$CholCheck)
binarydata$Smoker  = as.factor(binarydata$Smoker)

binarydata$Stroke  = as.factor(binarydata$Stroke)
binarydata$HeartDiseaseorAttack  = as.factor(binarydata$HeartDiseaseorAttack)
binarydata$PhysActivity  = as.factor(binarydata$PhysActivity)
binarydata$Fruits  = as.factor(binarydata$Fruits)

binarydata$Veggies  = as.factor(binarydata$Veggies)
binarydata$HvyAlcoholConsump  = as.factor(binarydata$HvyAlcoholConsump)
binarydata$AnyHealthcare  = as.factor(binarydata$AnyHealthcare)
binarydata$NoDocbcCost  = as.factor(binarydata$NoDocbcCost)

binarydata$DiffWalk  = as.factor(binarydata$DiffWalk)
binarydata$Sex  = as.factor(binarydata$Sex)
```

```{r}
#splitting the data into testing and training data set
set.seed(10)
data1 = sort(sample(nrow(binarydata), nrow(binarydata)*.70)) 
train.set1 = binarydata[data1,] 
test.set1 = binarydata[-data1,]
```

```{r}

#Logistic regression
library(MASS)
set.seed(10)
logistic.reg.model = glm(Diabetes_binary ~., data = train.set1 , family="binomial")
summary(logistic.reg.model)
```
```{r}
pred1 = predict(logistic.reg.model, test.set1, type = "response")
pred1.glm = rep(0, length(pred1))
pred1.glm[pred1 > 0.5] = 1
table(pred1.glm, test.set1$Diabetes_binary)
meanval1 = mean(pred1.glm != test.set1$Diabetes_binary)
meanval1

cat("Test error of the Logistic Regression model is", meanval1*100,"%")

```

```{r}
## cross-validation
diabetes3_ctrl<-trainControl(method="cv", number=5)
kfoldmodel3<-train(Diabetes_binary ~ ., 
                   data = train.set1,
                   method="lm", 
                  trControl = diabetes3_ctrl)
print(kfoldmodel3)
```

```{r}
##Lasso Regression

#install.packages("glmnet")
library(glmnet)

matrix.train.set1<- model.matrix(Diabetes_binary ~ ., data = train.set1) 
matrix.test.set1 <- model.matrix(Diabetes_binary ~ ., data = test.set1) 

grid <- 10 ^ seq(10, -2, length = 100) 

fit.lasso <- glmnet(matrix.train.set1, train.set1$Diabetes_binary, alpha = 1, lambda = grid, thresh = 1e-12)
set.seed(30)
##cross-validation
cv.lasso <- cv.glmnet(matrix.train.set1, train.set1$Diabetes_binary, alpha = 1, lambda = grid, thresh = 1e-12)
bestlam.lasso <- cv.lasso$lambda.min
bestlam.lasso

pred.lasso <- predict(fit.lasso, s = bestlam.lasso, newx = matrix.test.set1)
mean = mean((pred.lasso - test.set1$Diabetes_binary)^2)

cat("Test error of the Lasso Regression model is", mean*100,"%")
```

```{r}

#PCR
#fitting PCR model
library(pls)
set.seed(1)
fit.pcr <- pcr(Diabetes_binary ~ ., data = train.set1, scale = TRUE, validation = "CV")
summary(fit.pcr)
validationplot(fit.pcr, val.type = "MSEP")

#from cross-validation we identify that the number of components, M = 6 is the one where we get the lowest cross-validation error.
pred.pcr <- predict(fit.pcr, test.set1, ncomp = 6)  
mean2 =mean((pred.pcr - test.set1$Diabetes_binary)^2)

cat("Test error of the PCR model is", mean2*100,"%")
```

```{r}
#KNN

set.seed(10)
num.data1 = sort(sample(nrow(binarydata), nrow(binarydata)*.70))
num.train.set1 = binarydata[num.data1,]
num.test.set1 = binarydata[-num.data1,]

KNNtrain1 = cbind(num.train.set1$HighBP, num.train.set1$HighChol, num.train.set1$CholCheck, num.train.set1$BMI, num.train.set1$Smoker, num.train.set1$Stroke, num.train.set1$HeartDiseaseorAttack ,num.train.set1$PhysActivity ,num.train.set1$Fruits, num.train.set1$Veggies, num.train.set1$HvyAlcoholConsump, num.train.set1$AnyHealthcare, num.train.set1$NoDocbcCost, num.train.set1$GenHlth, num.train.set1$MentHlth, num.train.set1$PhysHlth, num.train.set1$DiffWalk, num.train.set1$Sex, num.train.set1$Age, num.train.set1$Education, num.train.set1$Income)
KNNtest1 = cbind(num.test.set1$HighBP, num.test.set1$HighChol, num.test.set1$CholCheck, num.test.set1$BMI, num.test.set1$Smoker, num.test.set1$Stroke, num.test.set1$HeartDiseaseorAttack ,num.test.set1$PhysActivity ,num.test.set1$Fruits, num.test.set1$Veggies, num.test.set1$HvyAlcoholConsump, num.test.set1$AnyHealthcare, num.test.set1$NoDocbcCost, num.test.set1$GenHlth, num.test.set1$MentHlth, num.test.set1$PhysHlth, num.test.set1$DiffWalk, num.test.set1$Sex, num.test.set1$Age, num.test.set1$Education, num.test.set1$Income)

KNN_Col1 = cbind("HighBP","HighChol","Cholcheck", "BMI", "Smoker", "Stroke", "Heart Disease", "Physical Activity", "Fruits", "Veggies", "Heavy Alchohol Consumption", "Any healthcare", "No doc cost","Gen health","Mental health","Physical health","Diff walk","Sex","Age","Education","Income")
colnames(KNNtrain1) = KNN_Col1
colnames(KNNtest1) = KNN_Col1

ncol(KNNtest1)
ncol(KNNtrain1)
#####################################
```

```{r}
library(class)
num.train.set1.Diabetes_binary = num.train.set1$Diabetes_binary
set.seed(1)
ncol(KNNtrain1)

nrow(KNNtrain1)

kNNModel1 = knn(KNNtrain1, KNNtest1, num.train.set1.Diabetes_binary, k = 5)
table(kNNModel1, num.test.set1$Diabetes_binary)
meanval1 = mean(kNNModel1 != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of the KNN model is", meanval1*100,"% for K= 5")
```

```{r}


kNNModel1 = knn(KNNtrain1, KNNtest1, num.train.set1.Diabetes_binary, k = 10)
table(kNNModel1, num.test.set1$Diabetes_binary)
meanval1 = mean(kNNModel1 != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of the KNN model is", meanval1*100,"% for K= 10")
```

```{r}
kNNModel1 = knn(KNNtrain1, KNNtest1, num.train.set1.Diabetes_binary, k = 35)
table(kNNModel1, num.test.set1$Diabetes_binary)
meanval1 = mean(kNNModel1 != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of the KNN model is", meanval1*100,"% for K= 35")
```

```{r}

kNNModel1 = knn(KNNtrain1, KNNtest1, num.train.set1.Diabetes_binary, k = 101)
table(kNNModel1, num.test.set1$Diabetes_binary)
meanval1 = mean(kNNModel1 != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of the KNN model with k=101 is", meanval1*100,"% for K= 101")

```

```{r}
##cross validation
trControl <- trainControl(method  = "cv",number  = 5)
it <- train(Diabetes_binary ~ .,
            method     = "knn",
            tuneGrid   = expand.grid(k = 1:10),
            trControl  = trControl,
            data       = test.set1)
print(it)
```

```{r}
#SVM with linear kernel
#library(e1071)
num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit <- svm(Diabetes_binary ~ ., data = num.train.set1, kernel = "linear", cost = 0.01)
summary(svc.fit)

train.pred <- predict(svc.fit,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred)

meanval1 = mean(train.pred != num.train.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with linear kernel is", meanval1*100)
```

```{r}

#cat("Training error rate is",(7267+5065)/(7267+5065+17505+19647))

test.pred <- predict(svc.fit, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred)


meanval1 = mean(test.pred != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of SVM with linear kernel is", meanval1*100)
```

```{r}
##cross-validation
# obj = tune.svm(Diabetes_binary ~ ., data=test.set1,cost=seq(from=0.005, to=1,by=0.005), gamma = 1)
# print(obj)
```

```{r}

# SVM with polynomial kernel degree=2
library(e1071)
num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit <- svm(Diabetes_binary ~ ., data = num.train.set1, kernel = "polynomial", degree=2)
summary(svc.fit)

train.pred <- predict(svc.fit,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred)

meanval1 = mean(train.pred != num.train.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with polynomial kernel degree 2 is", meanval1*100)

#cat("Training error rate is",(7907+4171)/(7907+4171+16865+20541))
```

```{r}
test.pred <- predict(svc.fit, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred)

meanval1 = mean(test.pred != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of SVM with polynomial kernel degree 2 is", meanval1*100)

#cat("Test error rate is",(3437+1917)/(7137+8717+3437+1917))
```

```{r}
# SVM with polynomial kernel degree=3
#library(e1071)
num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit <- svm(Diabetes_binary ~ ., data = num.train.set1, kernel = "polynomial", degree=3)
summary(svc.fit)

train.pred <- predict(svc.fit,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred)

meanval1 = mean(train.pred != num.train.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with polynomial kernel degree 3 is", meanval1*100)

#cat("Training error rate is",(7384+4612)/(7384+4612+17388+20100))

test.pred <- predict(svc.fit, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred)

meanval1 = mean(test.pred != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of SVM with polynomial kernel degree 3 is", meanval1*100)

#cat("Test error rate is",(3248+2173)/(3248+2173+7326+8461))
```

```{r}
# SVM with radial kernel

#library(e1071)
num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit <- svm(Diabetes_binary ~ ., data = num.train.set1, kernel = "radial")
summary(svc.fit)

train.pred <- predict(svc.fit,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred)

meanval1 = mean(train.pred != num.train.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with radial kernel is", meanval1*100)

#cat("Training error rate is",(7506+4369)/(7506+4369+17266+20343))
```

```{r}
test.pred <- predict(svc.fit, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred)

meanval1 = mean(test.pred != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of SVM with radial kernel is", meanval1*100)

#cat("Test error rate is",(3296+2065)/(3296+2065+7278+8569))
```

##cross-validation
<!-- folds = createFolds(train.set1$Diabetes_binary, k = 10) -->
<!-- cv = lapply(folds, function(x) {    -->
<!--   training_fold = train.set1[-x, ]  -->
<!--   test_fold = train.set1[x, ]  -->
<!--   classifier = svm(formula = Diabetes_binary ~ ., -->
<!--                    data = training_fold, -->
<!--                    type = 'C-classification', -->
<!--                    kernel = 'radial') -->
<!--   y_pred = predict(classifier, newdata = test_fold[-3]) -->
<!--   cm = table(test_fold[, 3], y_pred) -->
<!--   accuracy = (cm[1,1] + cm[2,2]) / (cm[1,1] + cm[2,2] + cm[1,2] + cm[2,1]) -->
<!--   return(accuracy) -->
<!-- }) -->

```{r}
# Random Forest
library(randomForest)
binarydata$Diabetes_binary = as.factor(binarydata$Diabetes_binary)

d.data1 = sort(sample(nrow(binarydata), nrow(binarydata)*.70)) 
d.train.set1 = binarydata[d.data1,] 
d.test.set1 = binarydata[-d.data1,]

levels(d.test.set1$Diabetes_binary)<-levels(d.train.set1$Diabetes_binary)
levels(d.test.set1$HighBP)<-levels(d.train.set1$HighBP)
levels(d.test.set1$HighChol)<-levels(d.train.set1$HighChol)
levels(d.test.set1$Smoker)<-levels(d.train.set1$Smoker)
levels(d.test.set1$Stroke)<-levels(d.train.set1$Stroke)
levels(d.test.set1$HeartDiseaseorAttack)<-levels(d.train.set1$HeartDiseaseorAttack)
levels(d.test.set1$PhysActivity)<-levels(d.train.set1$PhysActivity)
levels(d.test.set1$Veggies)<-levels(d.train.set1$Veggies)
levels(d.test.set1$HvyAlcoholConsump)<-levels(d.train.set1$HvyAlcoholConsump)
levels(d.test.set1$AnyHealthcare)<-levels(d.train.set1$AnyHealthcare)
levels(d.test.set1$NoDocbcCost)<-levels(d.train.set1$NoDocbcCost)
levels(d.test.set1$GenHlth)<-levels(d.train.set1$GenHlth)
levels(d.test.set1$MentHlth)<-levels(d.train.set1$MentHlth)
levels(d.test.set1$PhysHlth)<-levels(d.train.set1$PhysHlth)
levels(d.test.set1$DiffWalk)<-levels(d.train.set1$DiffWalk)
levels(d.test.set1$Sex)<-levels(d.train.set1$Sex)
levels(d.test.set1$Age)<-levels(d.train.set1$Age)
levels(d.test.set1$Education)<-levels(d.train.set1$Education)
levels(d.test.set1$Income)<-levels(d.train.set1$Income)

set.seed(123)
y_test <- d.test.set1["Diabetes_binary"]
fit1 <- randomForest(Diabetes_binary ~. , data=d.train.set1, mtry = 26, nTree=500, importance=TRUE,na.action=na.roughfix)
fit1
y_pred=predict(fit1,newdata = d.test.set1)
```

```{r}
#Using Importance to find out which variables are important
importance(fit1)
varImpPlot(fit1)
```

```{r}
t1=table(y_pred, d.test.set1$Diabetes_binary)
Accuracy = (t1[1,2] + t1[2,1]) / (dim(d.test.set1)[1])
cat("Error rate is ", Accuracy)
```

```{r}
##cross-validation 
numFolds <- trainControl(method = "cv", number = 10)
cpGrid <- expand.grid(.cp = seq(0.01, 0.5, 0.01))
train(Diabetes_binary ~., data = train.set1, method = "rpart", trControl = numFolds, tuneGrid = cpGrid)
```
#stevensTreeCV <- rpart(Diabetes_binary ~., data = train.set1, method = "class", cp = 0.02)
#predictionCV <- predict(stevensTreeCV, newdata = test.set1, type = "class")
#table(test.set1$Diabetes_binary, predictionCV)
#68.54

```{r}
### building model on significant variables

##Lasso Regression

#install.packages("glmnet")
library(glmnet)

matrix.train.set2<- model.matrix(Diabetes_binary ~ BMI + Age + HighBP + HighChol + GenHlth, data = train.set1) 
matrix.test.set2<- model.matrix(Diabetes_binary ~ BMI + Age + HighBP + HighChol + GenHlth, data = test.set1) 

grid2 <- 10 ^ seq(10, -2, length = 100) 

fit.lasso2<- glmnet(matrix.train.set2, train.set1$Diabetes_binary, alpha = 1, lambda = grid2, thresh = 1e-12)
set.seed(30)
cv.lasso2 <- cv.glmnet(matrix.train.set2, train.set1$Diabetes_binary, alpha = 1, lambda = grid2, thresh = 1e-12)
bestlam.lasso2 <- cv.lasso2$lambda.min
bestlam.lasso2

pred.lasso2 <- predict(fit.lasso2, s = bestlam.lasso2, newx = matrix.test.set2)
mean2 = mean((pred.lasso2 - test.set1$Diabetes_binary)^2)

cat("Test error of the Lasso Regression model is", mean2*100,"%")
```

```{r}

#Logistic regression
library(MASS)
set.seed(10)
logistic.reg.model1 = glm(Diabetes_binary ~ BMI + Age + HighBP + HighChol + GenHlth, data = train.set1 , family="binomial")
summary(logistic.reg.model1)

pred3 = predict(logistic.reg.model1, test.set1, type = "response")
pred3.glm = rep(0, length(pred3))
pred3.glm[pred3 > 0.5] = 1
table(pred3.glm, test.set1$Diabetes_binary)
meanval2 = mean(pred3.glm != test.set1$Diabetes_binary)
meanval2

cat("Test error of the Logistic Regression model is", meanval2*100,"%")


```

```{r}
# SVM with radial kernel

library(e1071)
num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit2 <- svm(Diabetes_binary ~ BMI + Age + HighBP + HighChol + GenHlth, data = num.train.set1, kernel = "radial")
summary(svc.fit2)

train.pred2 <- predict(svc.fit2,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred2)


cat("Training error rate is",(4700+7816)/(4700+7816+16956+20012))

test.pred2 <- predict(svc.fit2, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred2)


cat("Test error rate is",(3384+2130)/(3384+2130+7190+8504))
```

```{r}

# SVM with polynomial kernel degree=2
#library(e1071)
num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit <- svm(Diabetes_binary ~ BMI + Age + HighBP + HighChol + GenHlth, data = num.train.set1, kernel = "polynomial", degree=2)
summary(svc.fit)



train.pred <- predict(svc.fit,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred)


meanval1 = mean(train.pred != num.train.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with polynomial kernel degree=2 is", meanval1*100)

#cat("Training error rate is",(3899+8804)/(15968+20813+3899+8804))
```

```{r}
test.pred <- predict(svc.fit, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred)

meanval1 = mean(test.pred != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of SVM with polynomial kernel degree=2 is", meanval1*100)


#cat("Test error rate is",(3812+1789)/(3812+1789+6762+8845))
```

```{r}
#PCR with significant variables
#fitting PCR model
library(pls)
set.seed(1)
fit.pcr2 <- pcr(Diabetes_binary ~ BMI + Age + HighBP + HighChol + GenHlth, data = train.set1, scale = TRUE, validation = "CV")
summary(fit.pcr2)
validationplot(fit.pcr2, val.type = "MSEP")


```

```{r}

pred.pcr2 <- predict(fit.pcr2, test.set1, ncomp = 5)  
mean2 =mean((pred.pcr2 - test.set1$Diabetes_binary)^2)

cat("Test error of the PCR model is", mean2*100,"%")

```

```{r}

#Random forest
#Using only the top 5 significant variables:

set.seed(123)
y_test <- d.test.set1["Diabetes_binary"]
fit1 <- randomForest(Diabetes_binary ~ BMI + Age + HighBP + HighChol + GenHlth , data=d.train.set1, mtry = 26, nTree=500, importance=TRUE,na.action=na.roughfix)
fit1
y_pred=predict(fit1,newdata = d.test.set1)

#Using Importance to find out which variables are important
t1=table(y_pred, d.test.set1$Diabetes_binary)
Accuracy = (t1[1,1] + t1[2,2]) / (dim(d.test.set1)[1])
cat("Accuracy is ", Accuracy)
```
### After the project presentation, professor suggested to build models using BMI,Age,
### HighBP, HighChol as these are the parameters which a person can check using devices,
###but GenHlth can not be measured so we are dropping this variable and using the significant varaibles


```{r}
##Lasso Regression

#install.packages("glmnet")
library(glmnet)

matrix.train.set3<- model.matrix(Diabetes_binary ~ BMI + Age + HighBP + HighChol, data = train.set1) 
matrix.test.set3<- model.matrix(Diabetes_binary ~ BMI + Age + HighBP + HighChol, data = test.set1) 

grid3 <- 10 ^ seq(10, -2, length = 100) 

fit.lasso3<- glmnet(matrix.train.set3, train.set1$Diabetes_binary, alpha = 1, lambda = grid3, thresh = 1e-12)
set.seed(30)
cv.lasso3 <- cv.glmnet(matrix.train.set3, train.set1$Diabetes_binary, alpha = 1, lambda = grid3, thresh = 1e-12)
bestlam.lasso3 <- cv.lasso3$lambda.min
bestlam.lasso3

pred.lasso3 <- predict(fit.lasso3, s = bestlam.lasso3, newx = matrix.test.set3)
mean3 = mean((pred.lasso3 - test.set1$Diabetes_binary)^2)

cat("Test error of the Lasso Regression model is", mean3*100,"%")
```
#19.19%, the accuracy is 80.81%

```{r}
#Logistic regression
library(MASS)
set.seed(10)
logistic.reg.model2 = glm(Diabetes_binary ~ BMI + Age + HighBP + HighChol, data = train.set1 , family="binomial")
summary(logistic.reg.model2)
```

```{r}
pred4 = predict(logistic.reg.model2, test.set1, type = "response")
pred4.glm = rep(0, length(pred4))
pred4.glm[pred4 > 0.5] = 1
table(pred4.glm, test.set1$Diabetes_binary)
meanval3 = mean(pred4.glm != test.set1$Diabetes_binary)
meanval3

cat("Test error of the Logistic Regression model is", meanval3*100,"%")
```
#28.51%, accuracy is 71.49%

```{r}
## cross-validation
diabetes3_ctrl<-trainControl(method="cv", number=5)
kfoldmodel3<-train(Diabetes_binary ~ BMI + Age + HighBP + HighChol, 
                   data = train.set1,
                   method="lm", 
                   trControl = diabetes3_ctrl)
print(kfoldmodel3)
```

```{r}
# SVM with radial kernel

#library(e1071)
#num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
#num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit3 <- svm(Diabetes_binary ~ BMI + Age + HighBP + HighChol, data = num.train.set1, kernel = "radial")
summary(svc.fit3)

train.pred3 <- predict(svc.fit3,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred3)

meanval1 = mean(train.pred3 != num.train.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with radia kernel is", meanval1*100)

#cat("Training error rate of SVM with radial kernel is",(5840+7980)/(5840+7980+16792+18872))
```

```{r}
test.pred3 <- predict(svc.fit3, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred3)

meanval1 = mean(test.pred3 != num.test.set1$Diabetes_binary)
meanval1
cat("Test error of SVM with radia kernel is", meanval1*100)

#cat("Test error rate of SVM with radial kernel is",(3441+2592)/(3441+2592+7133+8042))
#28.44%, accuracy is 71.56%
```

```{r}

# SVM with polynomial kernel degree=2
#library(e1071)
#num.train.set1$Diabetes_binary = as.factor(num.train.set1$Diabetes_binary)
#num.test.set1$Diabetes_binary = as.factor(num.test.set1$Diabetes_binary)
set.seed(123)
svc.fit2 <- svm(Diabetes_binary ~ BMI + Age + HighBP + HighChol, data = num.train.set1, kernel = "polynomial", degree=2)
summary(svc.fit2)



train.pred2 <- predict(svc.fit2,num.train.set1)
table(num.train.set1$Diabetes_binary, train.pred2)

meanval1 = mean(train.pred2 != num.train.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with polynomial kernel degree=2 is", meanval1*100)

#cat("Training error rate is",(6451+8026)/(6451+8026+16746+18261))

```

```{r}

test.pred2 <- predict(svc.fit2, num.test.set1)
table(num.test.set1$Diabetes_binary, test.pred2)

meanval1 = mean(test.pred2 != num.test.set1$Diabetes_binary)
meanval1
cat("Train error of SVM with polynomial kernel degree=2 is", meanval1*100)

#cat("Test error rate is",(3451+2857)/(3451+2857+7123+7777))
#29.74%, accuracy is 70.26%
```

```{r}
#Random forest
library(randomForest)
#binarydata$Diabetes_binary = as.factor(binarydata$Diabetes_binary)

#d.data1 = sort(sample(nrow(binarydata), nrow(binarydata)*.70)) 
#d.train.set1 = binarydata[d.data1,] 
#d.test.set1 = binarydata[-d.data1,]

#levels(d.test.set1$Diabetes_binary)<-levels(d.train.set1$Diabetes_binary)
#levels(d.test.set1$HighBP)<-levels(d.train.set1$HighBP)
#levels(d.test.set1$HighChol)<-levels(d.train.set1$HighChol)
#levels(d.test.set1$Smoker)<-levels(d.train.set1$Smoker)
#levels(d.test.set1$Stroke)<-levels(d.train.set1$Stroke)
#levels(d.test.set1$HeartDiseaseorAttack)<-levels(d.train.set1$HeartDiseaseorAttack)
#levels(d.test.set1$PhysActivity)<-levels(d.train.set1$PhysActivity)
#levels(d.test.set1$Veggies)<-levels(d.train.set1$Veggies)
#levels(d.test.set1$HvyAlcoholConsump)<-levels(d.train.set1$HvyAlcoholConsump)
#levels(d.test.set1$AnyHealthcare)<-levels(d.train.set1$AnyHealthcare)
#levels(d.test.set1$NoDocbcCost)<-levels(d.train.set1$NoDocbcCost)
#levels(d.test.set1$GenHlth)<-levels(d.train.set1$GenHlth)
#levels(d.test.set1$MentHlth)<-levels(d.train.set1$MentHlth)
#levels(d.test.set1$PhysHlth)<-levels(d.train.set1$PhysHlth)
#levels(d.test.set1$DiffWalk)<-levels(d.train.set1$DiffWalk)
#levels(d.test.set1$Sex)<-levels(d.train.set1$Sex)
#levels(d.test.set1$Age)<-levels(d.train.set1$Age)
#levels(d.test.set1$Education)<-levels(d.train.set1$Education)
#levels(d.test.set1$Income)<-levels(d.train.set1$Income)

#Using the 4 significant variables:

set.seed(123)
y_test1 <- d.test.set1["Diabetes_binary"]
fit2 <- randomForest(Diabetes_binary ~ BMI + Age + HighBP + HighChol , data=d.train.set1, mtry = 26, nTree=500, importance=TRUE,na.action=na.roughfix)
fit2
y_pred=predict(fit2,newdata = d.test.set1)

#Using Importance to find out which variables are important
t2=table(y_pred, d.test.set1$Diabetes_binary)
error_rate = (t2[1,2] + t2[2,1]) / (dim(d.test.set1)[1])
cat("Error rate is ", error_rate*100)

```
